defaults:
  - backend: py-txi
  - launcher: process
  - benchmark: inference 
  - experiment 
  - _self_ # for hydra 1.1 compatibility
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

experiment_name: llama70B_8

backend:
  device: cuda
  no_weights: false
  model: "meta-llama/Llama-2-70b-chat-hf"

benchmark:
  input_shapes:
    batch_size: 8
    sequence_length: 2048
  new_tokens: 50
  memory: true

hydra:
  run:
    # where to store run results
    dir: runs/Llama70/${experiment_name}
  sweep:
    # where to store sweep results
    dir: sweeps/${experiment_name}
  job:
    chdir: true
    env_set:
      OVERRIDE_BENCHMARKS: 1